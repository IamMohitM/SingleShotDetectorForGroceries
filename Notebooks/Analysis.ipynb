{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "genuine-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prospective-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloaded from https://github.com/gulvarol/grocerydataset\n",
    "annotation_path = '../dataset/grocerydataset-master'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cosmetic-secondary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>b_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>1008</td>\n",
       "      <td>1552</td>\n",
       "      <td>1260</td>\n",
       "      <td>1928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>1028</td>\n",
       "      <td>928</td>\n",
       "      <td>1280</td>\n",
       "      <td>1304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>24</td>\n",
       "      <td>872</td>\n",
       "      <td>268</td>\n",
       "      <td>1264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>280</td>\n",
       "      <td>1568</td>\n",
       "      <td>532</td>\n",
       "      <td>1944</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>292</td>\n",
       "      <td>872</td>\n",
       "      <td>544</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_name   x_1   y_1   x_2   y_2  b_i\n",
       "0  C1_P01_N1_S2_1.JPG  1008  1552  1260  1928    0\n",
       "1  C1_P01_N1_S2_1.JPG  1028   928  1280  1304    0\n",
       "2  C1_P01_N1_S2_1.JPG    24   872   268  1264    0\n",
       "3  C1_P01_N1_S2_1.JPG   280  1568   532  1944    0\n",
       "4  C1_P01_N1_S2_1.JPG   292   872   544  1248    0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"image_name\", \"x_1\", \"y_1\", \"x_2\", \"y_2\", \"b_i\"]\n",
    "master_df = pd.read_csv(os.path.join(annotation_path, \"annotations.csv\"), \n",
    "                        names=cols)\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "governmental-timber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  4,  7,  3,  6, 10,  2,  5,  8,  9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df['b_i'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-purchase",
   "metadata": {},
   "source": [
    "### Finding the average Aspect Ratio\n",
    "\n",
    "Since we can only have one anchor box per feature map cell, it's important to understand the aspect ratio distribution in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "thirty-reason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>b_i</th>\n",
       "      <th>ar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>1008</td>\n",
       "      <td>1552</td>\n",
       "      <td>1260</td>\n",
       "      <td>1928</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>1028</td>\n",
       "      <td>928</td>\n",
       "      <td>1280</td>\n",
       "      <td>1304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>24</td>\n",
       "      <td>872</td>\n",
       "      <td>268</td>\n",
       "      <td>1264</td>\n",
       "      <td>0</td>\n",
       "      <td>0.622449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>280</td>\n",
       "      <td>1568</td>\n",
       "      <td>532</td>\n",
       "      <td>1944</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>292</td>\n",
       "      <td>872</td>\n",
       "      <td>544</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_name   x_1   y_1   x_2   y_2  b_i        ar\n",
       "0  C1_P01_N1_S2_1.JPG  1008  1552  1260  1928    0  0.670213\n",
       "1  C1_P01_N1_S2_1.JPG  1028   928  1280  1304    0  0.670213\n",
       "2  C1_P01_N1_S2_1.JPG    24   872   268  1264    0  0.622449\n",
       "3  C1_P01_N1_S2_1.JPG   280  1568   532  1944    0  0.670213\n",
       "4  C1_P01_N1_S2_1.JPG   292   872   544  1248    0  0.670213"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df['ar'] = (master_df['x_2'] - master_df['x_1'])/(master_df['y_2'] - master_df['y_1'])\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "legal-customer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  5.,  22.,  77., 380., 857., 843., 433., 102.,  21.,   4.]),\n",
       " array([0.42056075, 0.47225467, 0.5239486 , 0.57564252, 0.62733645,\n",
       "        0.67903037, 0.7307243 , 0.78241822, 0.83411215, 0.88580607,\n",
       "        0.9375    ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(master_df.loc[master_df['b_i']!=0, 'ar'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "american-berry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6589409662173765"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df['ar'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "connected-ferry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07013425480860264"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df['ar'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "working-bikini",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.666667    441\n",
       "0.750000    137\n",
       "0.714286    128\n",
       "0.700000    114\n",
       "0.647059    110\n",
       "           ... \n",
       "0.616162      1\n",
       "0.561983      1\n",
       "0.534247      1\n",
       "0.707547      1\n",
       "0.495146      1\n",
       "Name: ar, Length: 1285, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df['ar'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-spell",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bizarre-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "shelf_image_path = '../dataset/GroceryDataset_part1.tar-2/ShelfImages'\n",
    "train_images = os.listdir(os.path.join(shelf_image_path, 'train'))\n",
    "test_images = os.listdir(os.path.join(shelf_image_path, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "elder-blues",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "smooth-minutes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-contact",
   "metadata": {},
   "source": [
    "We want to split 10% of the training images for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceramic-cream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "golden-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_images = np.random.choice(train_images,\n",
    "                                 size=int(len(train_images) * 0.1),\n",
    "                                 replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-albany",
   "metadata": {},
   "source": [
    "Before splitting the dataset, we should add the brand_ids by one since during training we'd want the background images to be labeled as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "marine-spell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>b_i</th>\n",
       "      <th>ar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>1008</td>\n",
       "      <td>1552</td>\n",
       "      <td>1260</td>\n",
       "      <td>1928</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>1028</td>\n",
       "      <td>928</td>\n",
       "      <td>1280</td>\n",
       "      <td>1304</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>24</td>\n",
       "      <td>872</td>\n",
       "      <td>268</td>\n",
       "      <td>1264</td>\n",
       "      <td>1</td>\n",
       "      <td>0.622449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>280</td>\n",
       "      <td>1568</td>\n",
       "      <td>532</td>\n",
       "      <td>1944</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1_P01_N1_S2_1.JPG</td>\n",
       "      <td>292</td>\n",
       "      <td>872</td>\n",
       "      <td>544</td>\n",
       "      <td>1248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_name   x_1   y_1   x_2   y_2  b_i        ar\n",
       "0  C1_P01_N1_S2_1.JPG  1008  1552  1260  1928    1  0.670213\n",
       "1  C1_P01_N1_S2_1.JPG  1028   928  1280  1304    1  0.670213\n",
       "2  C1_P01_N1_S2_1.JPG    24   872   268  1264    1  0.622449\n",
       "3  C1_P01_N1_S2_1.JPG   280  1568   532  1944    1  0.670213\n",
       "4  C1_P01_N1_S2_1.JPG   292   872   544  1248    1  0.670213"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df['b_i'] = master_df['b_i'] + 1\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "radical-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = master_df.loc[master_df['image_name'].isin(train_images)]\n",
    "test_df = master_df.loc[master_df['image_name'].isin(test_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "endless-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = train_df.loc[train_df['image_name'].isin(random_images)]\n",
    "train_df = train_df.loc[~train_df['image_name'].isin(random_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "affecting-parking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9553, 7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deluxe-profession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(983, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "australian-christmas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2648, 7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "severe-technical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13184, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv(os.path.join(shelf_image_path, 'training_annotations_split.csc'), index=False)\n",
    "# val_df.to_csv(os.path.join(shelf_image_path, 'validation_annotations_split.csc'), index=False)\n",
    "# test_df.to_csv(os.path.join(shelf_image_path, 'testing_annotations_split.csc'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-ideal",
   "metadata": {},
   "source": [
    "### Identifying the weights for Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "optical-empty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     7646\n",
       "3      649\n",
       "5      292\n",
       "2      240\n",
       "8      214\n",
       "9      147\n",
       "7      130\n",
       "6       79\n",
       "10      62\n",
       "11      50\n",
       "4       44\n",
       "Name: b_i, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df['b_i'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-rebate",
   "metadata": {},
   "source": [
    "Since the dataset is highly imbalanced, we'd like to weigh the loss function accordingly. We weigh each class by the reciprocal of it's frequency in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "educational-rider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1.2628352490421457,\n",
       " 2: 43.368421052631575,\n",
       " 3: 13.210420841683366,\n",
       " 4: 196.77611940298507,\n",
       " 5: 32.0,\n",
       " 6: 115.64912280701755,\n",
       " 7: 69.38947368421053,\n",
       " 8: 42.39228295819936,\n",
       " 9: 67.61025641025641,\n",
       " 10: 169.02564102564102,\n",
       " 11: 175.78666666666666}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = (1/(master_df['b_i'].value_counts()/master_df.shape[0])).sort_index().to_dict()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "small-respondent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0065, 0.2218, 0.0676, 1.0065, 0.1637, 0.5915, 0.3549, 0.2168, 0.3458,\n",
       "        0.8645, 0.8991])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizing the weights\n",
    "weights = torch.tensor(list(class_weights.values()))\n",
    "weights = (weights)/(weights.max().item() - weights.min().item())\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "decreased-actor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.006459076423197985,\n",
       " 0.22181826829910278,\n",
       " 0.06756789237260818,\n",
       " 1.00645911693573,\n",
       " 0.16367173194885254,\n",
       " 0.5915154218673706,\n",
       " 0.3549092411994934,\n",
       " 0.21682558953762054,\n",
       " 0.3458090126514435,\n",
       " 0.8645224571228027,\n",
       " 0.8991034030914307]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [w.item() for w in weights]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "general-consultation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.006459076423197985,\n",
       " 2: 0.22181826829910278,\n",
       " 3: 0.06756789237260818,\n",
       " 4: 1.00645911693573,\n",
       " 5: 0.16367173194885254,\n",
       " 6: 0.5915154218673706,\n",
       " 7: 0.3549092411994934,\n",
       " 8: 0.21682558953762054,\n",
       " 9: 0.3458090126514435,\n",
       " 10: 0.8645224571228027,\n",
       " 11: 0.8991034030914307}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(range(1, 12), weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-effort",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l] *",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
